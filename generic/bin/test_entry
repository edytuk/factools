#!/usr/bin/python
import sys
import os
import tempfile
import time
import shutil
import re
import getopt

STARTUP_DIR=sys.path[0]

#sys.path.append(os.path.join(STARTUP_DIR,".."))
#sys.path.append(os.path.join(STARTUP_DIR,"../../lib"))
# get source dir from env var until we push upstream to glideinWMS
if 'GLIDEIN_SRC_DIR' in os.environ:
    sys.path.append(os.path.join(os.environ['GLIDEIN_SRC_DIR'], "factory"))
    sys.path.append(os.path.join(os.environ['GLIDEIN_SRC_DIR'], "lib"))
else:
    print '"GLIDEIN_SRC_DIR" not defined. exiting.'
    sys.exit(1)

import condorManager
import glideFactoryConfig
import condorLogParser
import condorPrivsep
import condorExe
import glideFactoryLib

#globals
# statuses of lost connections
lost_con_stats=('020','026','022','010','029')
verbose = False

'''def createSubmitFile(sfile,log_dir,
                     script_file, timeout, grid_type, gatekeeper):
    fd=open(sfile,"w")
    try:
        fd.write("universe=grid\n")
        fd.write("grid_resource=%s %s\n" % (grid_type, gatekeeper))
        fd.write("executable=%s\n"%script_file)
        fd.write("copy_to_spool=True\n")
        fd.write("output=%s\n"%os.path.join(log_dir,"testpilot.$(Cluster).$(Process).out"))
        fd.write("error=%s\n"%os.path.join(log_dir,"testpilot.$(Cluster).$(Process).err"))
        fd.write("log=%s\n"%os.path.join(log_dir,"testpilot.$(Cluster).$(Process).log"))
        fd.write("transfer_executable=True\n")
        fd.write("when_to_transfer_output=ON_EXIT\n")
        fd.write("notification=Never\n")
        #fd.write("periodic_remove=(CurrentTime>%li)\n"%(long(time.time())+timeout+30)) # karakiri after timeout+delta
        fd.write("stream_output=False\n")
        fd.write("stream_error=False\n")
        fd.write("queue\n")
    finally:
        fd.close()
'''

def create_submit_file(sub_file, script_file, glide_desc, job_desc, user, args=None, fork=False):
    log_dir = "%s/user_%s/glidein_%s/test" % (glide_desc.data['ClientLogBaseDir'],user,glide_desc.data['GlideinName'])
    ent_name = job_desc.data['EntryName']
    grid_type = job_desc.data['GridType']

    if fork:
        # assume fork only works for globus
        if grid_type not in ('gt2', 'gt5'):
            raise ValueError, 'fork is unsupported for gridtype "%s"' % grid_type
        gatekeeper = re.sub(r'jobmanager-.*$','jobmanager-fork', job_desc.data['Gatekeeper'])
    else:
        gatekeeper = job_desc.data['Gatekeeper']

    rsl = None
    if 'GlobusRSL' in job_desc.data:
        # assume rsl only works for globus and nordugrid
        if grid_type not in ('gt2', 'gt5', 'nordugrid'):
            raise RuntimeError, 'Config error: gridtype "%s" does not support rsl' % grid_type
        rsl = job_desc.data['GlobusRSL']

    logs = [os.path.join(log_dir,"testpilot_%s.log" % ent_name),
        os.path.join(log_dir,"testpilot_%s.$(Cluster).$(Process).out" % ent_name),
        os.path.join(log_dir,"testpilot_%s.$(Cluster).$(Process).err" % ent_name)]

    fd=open(sub_file,"w")
    try:
        fd.write("universe=grid\n")
        fd.write("grid_resource=%s %s\n" % (grid_type, gatekeeper))
        if rsl is not None:
            if grid_type == 'gt2' or grid_type == 'gt5':
                fd.write("globus_rsl=%s\n" % rsl)
            elif grid_type == 'nordugrid':
                fd.write("nordugrid_rsl=%s\n" % rsl)
        fd.write("executable=%s\n"%script_file)
        if args is not None:
            fd.write("arguments=%s\n" % (" ".join(args)))
        fd.write("copy_to_spool=True\n")
        fd.write("log=%s\n" % logs[0])
        fd.write("output=%s\n" % logs[1])
        fd.write("error=%s\n" % logs[2])
        fd.write("transfer_executable=True\n")
        fd.write("when_to_transfer_output=ON_EXIT\n")
        fd.write("notification=Never\n")
        #fd.write("periodic_remove=(CurrentTime>%li)\n"%(long(time.time())+timeout+30)) # karakiri after timeout+delta
        fd.write("stream_output=False\n")
        fd.write("stream_error=False\n")
        fd.write("queue\n")
    finally:
        fd.close()
    return logs

def create_script(out_file, sleep_time=300):
    fd = open(out_file, "w")
    try:
        fd.write('#!/bin/sh\n')
        fd.write('echo "Date: `date`"\n')
        fd.write('echo "Whoami: `whoami`"\n')
        fd.write('echo "System: `uname -a`"\n')
        fd.write('echo "PWD: `echo $PWD`"\n')
        fd.write('echo\n')
        fd.write('echo "Environment:"\n')
        fd.write('env\n')
        fd.write('echo\n')
        fd.write('echo "Sleeping for %s seconds."\n' % sleep_time)
        fd.write('sleep %s\n' % sleep_time)
        fd.write('echo "Done."\n')
    finally:
        fd.close()

# returns tuple (True | False,status,message) True if job does not require removal (terminated or aborted) 
def checkFile(fname,schedd_name, timeout):
    interval = 5
    deadline=time.time()+timeout
    ptime = -1 # force the file to be read the first time
    while True:
        mtime = os.path.getmtime(fname)

        if mtime > ptime:
            status,message = getLastLogStatus(fname)
            if verbose:
                print message
            # terminated or aborted
            if status == '005' or status == '009':
                return (True, status, message)
            # failed to submit, held, or connection lost
            elif status == '018' or status == '012' or status in lost_con_stats:
                return (False, status, message)

        time.sleep(interval)

        if time.time() > deadline:
            break
        
        ptime = mtime

    raise RuntimeError, "Command did not reply within timeout (%ss)"%timeout

def printFile(fname,outfd):
    fd=open(fname)
    try:
        data=fd.read()
        outfd.write(data)
    finally:
        fd.close()

def getLastLogStatus(fname):
    fin = open(fname)
    
    lines = fin.readlines()
    fin.close()

    # could i have done a for loop with negatives instead?
    cur = len(lines)-1
    end = -1
    start = -1
    while cur >= 0:
        if lines[cur].startswith('...'):
            end = cur
        elif lines[cur][:3].isdigit():
            start = cur
            status = lines[cur][:3]
            break
        cur -= 1

    # if can't find status number throw error
    if start == -1:
        raise RuntimeError, "Error retrieving status in:%s" % fname

    # if couldn't find '...' string just print to eof
    if end == -1:
        end = len(lines)-1
        
    # could i have done a for loop with negatives instead?
    message = ""
    for i in range(start,end+1):
        message += lines[i]
    
    message = message.rstrip()
    return status,message

# should we ever attempt without privsep like glidein does?
def priv_submit(username, sub_file, x509_proxy_fname, schedd_name=None):
    cond_sub_path = condorExe.iexe_cmd("which condor_submit")[0][:-1]
    exe_env=['X509_USER_PROXY=%s'%x509_proxy_fname]
    for var in os.environ.keys():
                        if ((var in ('PATH','LD_LIBRARY_PATH','X509_CERT_DIR')) or
                            (var[:8]=='_CONDOR_') or (var[:7]=='CONDOR_')):
                            if os.environ.has_key(var):
                                exe_env.append('%s=%s'%(var,os.environ[var]))

    if schedd_name is None:
        submit_out=condorPrivsep.execute(username,".",cond_sub_path,[cond_sub_path,sub_file],exe_env)
    else:
        submit_out=condorPrivsep.execute(username,".",cond_sub_path,[cond_sub_path,'-name',schedd_name,sub_file],exe_env)
    cluster,count=glideFactoryLib.extractJobId(submit_out)
    return submit_out,cluster,count

# what if user / entry create invalid path?
'''def getLogDir(user, entry):
    glide_conf = glideFactoryConfig.GlideinDescript()
    return os.path.join(glide_conf.data['ClientLogBaseDir'],"user_%s/glidein_%s/entry_%s"
        % (user, glide_conf.data['GlideinName'],entry))
'''

def get_proxy_dir(glide_desc, job_desc, user):
    return "%s/user_%s/glidein_%s/entry_%s" %(glide_desc.data['ClientProxiesBaseDir'],user,
        glide_desc.data['GlideinName'],job_desc.data['EntryName'])

# return list of proxies
def proxy_ls(user, proxy_dir):
    out = condorPrivsep.execute(user,'.','/bin/ls',['/bin/ls',proxy_dir])
    # strip away newline chars
    return [i[:-1] for i in out]

# return long list of proxies; time sorted
def proxy_lslt(user, proxy_dir):
    out = condorPrivsep.execute(user,'.','/bin/ls',['/bin/ls', '-lt', proxy_dir])
    # strip away newline chars
    return [i[:-1] for i in out]

def get_proxy_life(user, proxy_file):
    try:
        voms_path=condorExe.iexe_cmd("which voms-proxy-info")[0][:-1]
    except:
        print "ERROR: voms-proxy-info not found, but needed"
        return 1

    env=[]
    for k in os.environ.keys():
       env.append('%s=%s'%(k,os.environ[k]))

    out = condorPrivsep.execute(user,'.',voms_path,[voms_path, '-dont-verify-ac', '-timeleft', '-file', proxy_file],env)
    return int(out[0][:-1])

def print_help():
    print '''\
Usage: test_entry [OPTIONS] USER ENTRY [SCRIPT] [ARGS..]

OPTIONS:
-h      prints this message
-f      run as fork job'''

if __name__ == "__main__":
    try:
        opts,args = getopt.getopt(sys.argv[1:],'hf')
    except getopt.GetoptError:
        print_help()
        sys.exit(1)

    fork = False
    for opt in opts:
        if opt[0] == '-h':
            print_help()
            sys.exit(0)
        if opt[0] == '-f':
            fork = True

    if len(args) < 2:
        print_help()
        sys.exit(1)

    user = args[0]
    entry = args[1]

    script_args = None

    if len(args) > 2:
        script_infile = args[2]
        if not os.path.exists(script_infile):
            sys.stderr.write("Script file %s does not exist! Exiting.\n")
            sys.exit(1)
        if len(args) > 3:
            script_args = args[3:]
        mode = "ext"
    else:
        mode = "int"

    glide_desc = glideFactoryConfig.GlideinDescript()
    job_desc = glideFactoryConfig.JobDescript(entry)

    proxy_dir = get_proxy_dir(glide_desc, job_desc, user)
    out = proxy_lslt(user, proxy_dir)

    if len(out) <= 1:
        sys.stderr.write("Could not find pilot proxies! Exiting.\n")
        sys.exit(1)

    #for p in proxies:
    #    if not p.endswith('.old'):
    #        print "%s Seconds Left: %s" % (p, get_proxy_life(user, "%s/%s" % (proxy_dir, p)))

    count = 0
    proxies = []
    
    proxy_select_list = []
    for line in out[1:]:
        if not line.endswith('.old'):
            proxies.append(line.split()[8])
            proxy_select_list.append("[%s] %s" % (count,line))
            count += 1

    if len(proxies) == 0:
        sys.stderr.write("Only found old pilot proxies! Exiting.\n")
        sys.exit(1)

    print "Select proxy from %s:" % (proxy_dir)
    for line in proxy_select_list:
        print line
    
    while True:
        try:
            num = int(raw_input("[0-%s]:" % (len(proxies) - 1)))
            if num >= 0 and num < len(proxies):
                break
        except ValueError:
            print "Input must be an integer [0-%s]." % (len(proxies) - 1)

    proxy = "%s/%s" % (proxy_dir, proxies[num])
    
    #schedd_name=job_desc.data['Schedd']
    
    tmpdir = tempfile.mkdtemp(prefix="testpilot_")

    try:
        os.chmod(tmpdir, 0755)
        sub_file = os.path.join(tmpdir, "job.condor")
        if mode == "int":
            script_file = os.path.join(tmpdir, "testpilot.sh")
        elif mode == "ext":
            script_file = os.path.join(tmpdir, os.path.basename(script_infile))
        user_dir = "%s/user_%s/glidein_%s" % (glide_desc.data['ClientLogBaseDir'],user,glide_desc.data['GlideinName'])
        if not os.path.exists("%s/test" % user_dir):
            condorPrivsep.execute(user,user_dir,'/bin/mkdir',['/bin/mkdir','test'])

        if mode == "int":
            create_script(script_file)
        elif mode == "ext":
            shutil.copyfile(script_infile, script_file)
            os.chmod(script_file, 0644)

        #createSubmitFile(sub_file, log_dir, script_file, timeout, grid_type, gatekeeper)
        logs = create_submit_file(sub_file, script_file, glide_desc, job_desc, user, script_args, fork)
        
        out,cluster,count = priv_submit(user, sub_file, proxy)
        for i in out:
            print i,
        
        print "Log files:"
        print logs[0]
        for l in logs[1:]:
            l = re.sub(r'\$\(Cluster\)',str(cluster),l)
            print re.sub(r'\$\(Process\)','*',l)
        
    finally:
        shutil.rmtree(tmpdir)
    
